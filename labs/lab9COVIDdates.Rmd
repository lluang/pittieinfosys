---
title: "Lab 9: Dates - COVID-19 in the U.S."
author: "Louis Luangkesorn"
date: "3/26/2020"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(purrr)
library(lubridate)
library(ggplot2)
```

## Working with dates and times

This assignment will work with the data used with the COVID-19 dashboard created by The Johns Hopkins University (JHU) Center for Systems Science and Engineering (CSSE). The JHU CSSE aggregates reports from DXY (Chinese medical community aggregating local media and government reports), and various national and state government agencies (the country equivalents to the U.S. CDC internationally and aggregating state or territory health authorities were these are available). Note that the use of verified media and government reports has been ahead of WHO and CDC reported numbers (i.e. the WHO and CDC report compilers are slower than JHU and their aggregators), so this is the cause of any discrepancy you may have seen (think 4 V's). The JHU numbers are the ones that most established media agencies and academic and research centers of public health are using.

The data provided are not in tidy format and are difficult to work with in models. In order to make the data usable, it will require a combination of tidy data, string processing, and date processing. A skeloton of the process is here, but you will have to fill in the gaps.

Download the daily reports data from Courseweb into a directory, then unzip it. Next, to load the data, replace the `datadirectory` line in the next chunk with the appropriate directory path.  Use your Windows Explorer or Finder (Mac OSX to assist you if you do not know how).  Note the use of `\\` for separating directory names (escape character to use the `\`).  The alternative is to replace all of the `\` with `/`.

The code below reads in the data for all of the data files and puts them into a single dataframe. Note that the data format changes over the course of the data collection, so the dates are read in as character.

```{r readdataset}
#datadirectory <- "C:\\Users\\louis\\Documents\\projects\\infectiousdisease\\COVID-19\\csse_covid_19_data\\csse_covid_19_daily_reports"
datadirectory <- "~/Documents/projects/sirmodels/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports"


datafiles <- list.files(datadirectory)
```
```{r}
coviddaily <- datafiles[50:length(datafiles)-1] %>%
  map(function(x) read_csv(file.path(datadirectory, x), 
                           col_types = cols(`Province/State` = col_character(),
                                `Country/Region` = col_character(),
                                `Last Update` = col_character(),
                                Confirmed = col_integer(),
                                Deaths = col_integer(),
                                Recovered = col_integer()
                                ))) %>%  
  reduce(rbind)

```

## 1. [5] Convert date types

There are two types of data format.  Starting in February, the format changed to YYYY-MM-DD HH:MM:SS (with an optional 'T' between DD and HH).

a. Using lubridate, convert the date from character to a date format and then only keep the date (removing the time stamp) save the result into a datefield. 
**ANSWER**
```{r convert dates}
coviddaily <- coviddaily %>%
  mutate(datetype = date(ymd_hms(`Last Update`)))
```
## [6] U.S. states

We are interested in spread in the U.S.  Currently, cases are reported by state, county, or city. To make these comparable, we want to report cases by state.

a.  Filter the COVID data to remove cases involving the Diamond Princess.
b.  Filter the COVID data to include only U.S. cases and then extract the state from the Province/State field (using stringr methods with regular expressions) 

- Note: you want to make sure you do not count cases from the Diamond Princess
- Note: like all regular expression problems developing the solutions are not simple, even if the final solution may be.  Write a flow chart and talk through it with a classmate/friend first before you start coding.

**ANSWER**
```{r}
covidus <- coviddaily %>%
  filter(!str_detect(`Province/State`, "Princess"), 
         !str_detect(`Province/State`, "[C|c]ruise"),
         !str_detect(`Country/Region`, "[C|c]ruise")) %>%
  filter(`Country/Region`=="US")
```

## [9] Plotting cases

The standard epidemic model is Susceptible - Infected - Removed (SIR). However, the data is Confirmed-Deaths-Recovered.  

a. Convert the data provided into SIR (note, no need to plot Susceptible) using:

- Removed = Deaths + Recovered
- Infected = Confirmed - Deaths - Recovered

b. Determine the six states with the most confirmed cases. Note that you need to group the data by state to do this. Note: because of NAs, use the option `na.rm=TRUE` for any summary function that needs it.

c. Plot the Infected and Removed over time for the three states with the most confirmed cases.  Note that you need to use the data summarized by state to do this.

**ANSWER**
```{r }
covidus <- covidus %>%
  group_by(`Province/State`, datetype) %>%
  summarize(Confirmed = sum(Confirmed, na.rm = TRUE),
            Deaths = sum(Deaths, na.rm=TRUE),
            Recovered =  sum(Recovered, na.rm=TRUE)) %>%
  mutate(Removed = Deaths + Recovered,
         Infected = Confirmed - Deaths - Recovered)
```



```{r}
topstates <- covidus %>%
  filter(!is.na(`Province/State`)) %>%
  group_by(`Province/State`) %>%
  summarize(Confirmed = max(Confirmed)) %>%
  arrange(desc(Confirmed)) %>%
  select(`Province/State`) %>%
  head(6) 

```

```{r}
covidtop9 <- covidus %>% 
  filter(`Province/State` %in% topstates$`Province/State`)
ggplot(covidtop9) +
  geom_line(aes(x=datetype, y=Infected), color="red") +
  geom_line(aes(x=datetype, y=Removed), color="blue") + 
  facet_wrap(.~`Province/State`)+
  scale_x_date() 
```

Note: On occasion in the early part of an epidemic, some shifts in cases reports are due to changing definitions and rules on reporting cases.