---
title: "Lecture 11 bootstrap and time step simulation"
author: "Louis Luangkesorn: IE 0015"
date: "April 2020"
output:
  pdf_document: default
  beamer_presentation:
    colortheme: whale
    theme: AnnArbor
    fig_height: 2
    fig_width: 4
  html_document: default
  slidy_presentation: default
---


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)

```



Simulation in data analysis
=============================

-  Simulation is the use of sampling through random numbers to obtain a distribution of a dependent variable.
-  e.g. Discrete event simulation (IE 1083), Monte Carlo simulation
-  Useful when we do not have a direct way of determining the value of a dependent variable.

Some types of computer simulation
================

-  Monte Carlo (last week)
-  Bootstrap (resampling) (this week)
-  Time step simulation  (this week)
-  Discrete event simulation (IE 1083)
-  Continuous simulation
-  Agent based simulation

Why simulation
==============

- No analytic solution (no equation that matches the system without violating assumptions)
- Need a distribution as output
    - Performance measure something other than mean or standard deviation
    - Quantile, threshold, max, min

Bootstrap
======

- Purpose:  Hypothesis testing in settings where there is limited data
- Data may NOT come from a normal distribution
- Bootstrap methods do not have as many assumptions

Resampling methods
==============================

-  Each determination of the dependent variable (performance measure) based on random simulation is a *sample*.
-  Results in a *sampling distribution* of the dependent variable.
    - Note: this is *not* the same as a single, "correct" answer.
    - Answers in statistics are given as probability distributions.
        - "There is a 95% probability that the true average is between __ and __"
-  We assume there is a true underlying distribution. The simulation allows us to have an estimate of it.

Advantages of simulation
==============================

-  Fewer assumptions:  we do not require that the underlying population is normally distributed or that the sample size is large or any of the assumptions required in stochastic models.
-  Greater accuracy: Many statistical methods are based on having rough upper bounds or use Taylor series expansions.  Simulations can be replicated based on the desired accuracy.
-  Generality - Resampling methods can be applied to a large class of problems, so do not require developing and implementing methods specific to that problem definition.
-  Actually determines probability.  Bayesian methods generate true probabilities.  Hypothesis testing methods do not (you are not supposed to treat a p-value as a probability)
-  What if? - We can use samples to create a study population with certain characteristics (e.g. oversample currently underrepresented sub-population) and explore what would happen if the current population changes. (e.g. scale a probability distribution)


Using bootstrap sampling
=======================

-  We have a small enough of observed data but not enough to identify a distribution.
-  *Bootstrap* - resample with replacement from the observed data.

Steps in the bootstrap
=========================
1.  Create samples of the independent variables $x_1^*, ..., x_M^*$, called *resamples*, by sampling *with replacement* from the data (control group).

2.  Calculate the statistic of interest $S(x_1^*), ..., S(x_M^*)$ for each resample. The distribution of the result of the resample is the *bootstrap distribution*.

3.  The bootstrap distribution gives information about the sampling distribution of the original, unobservable, statistic *S*.  It gives an approximation of the center, spread, and shape of *S*.

Standard errors
=================

-  Errors from bootstrapping come from two sources
    -  The observed data does not the same exact distribution as the population from which it was drawn.
    -  The resampled sample will have a different distribution than the observed data.
  
Standard error example
============================

-  Look at a sample where the underling population is normally distributed $X \sim N(\mu=3, \sigma=1)$.
-  Look at $\bar{x}$
-  We know that $\bar{x} \sim N(\mu, 1/\sqrt{n})$
-  Take mean of 25 samples $N(3,1)$ (sd = $1/\sqrt{25}$)
-  1000 samples

Example
=====


```{r}
options(digits=2)
srs <- rnorm(25, mean = 3)
resamps <- replicate(1000, sample(srs, 25, TRUE), simplify = FALSE)
xbarstar <- sapply(resamps, mean, simplify = TRUE)
hist(xbarstar, breaks = 40, prob = TRUE, xlim=c(2, 4),
  main="Mean of 25 N(3,1) distributions, 1000 replications",
  xlab="Mean of replication")
curve(dnorm(x, 3, 0.2), add = TRUE)
```

Compare simulation to the theoretical mean
=========================================

-  Expected confidence interval of the mean
    - $sd/\sqrt{n} = 1/\sqrt{25} = 0.2$
```{r}
print(mean(xbarstar), digits=10)
print(sd(xbarstar), digits=10)
```
-  Within expectation

Improving the errors
======================

-  What would happen if we took more samples?
-  More samples would make the sample look more like the observed data.
    - Does not make the observed data closer to the true underlying population distribution.
  
Implementing using the boot package
===================

-  The function `boot` is in the *boot* package.
-  Define a summary function, then apply it using bootstrap.

```{r}
library(boot)
mean_fun <- function(x, indices) mean(x[indices])
boot(data = srs, statistic = mean_fun, R = 1000)
```

Try the same thing with a different statistic
========================

```{r}
median_fun <- function(x, indices) median(x[indices])
riversboot <- boot(data = rivers, statistic = median_fun, R = 1000)
print(riversboot)
hist(riversboot$t, main="Distribution of median of 25 sample", xlab = "median of 25 values")
```



Confidence intervals
===================

- Typically, we calculated confidence intervals by assuming that outputs were normally distributed.
    - e.g. use c.i. as a function of the *t*-distribution.
- Using simulation, we can apply the definition of the c.i. directly.
    - "95% of the estimates are between __ and __"
    - Using simulation, use the 0.025 and 0.975 quantiles of the simulation results. (e.g. equal tails)
    - Another choice is to use the smallest range that gives a 0.95 interval.
        - Question: Why are these not the same thing?
    
C.I. example
====================

Using Operational data of a plant for the oxidation of ammonia to nitric acid.

```{r}
data("stackloss")
btsamps <- replicate(2000, sample(stackloss$stack.loss, 21, replace=TRUE), simplify = FALSE)
thetast <- sapply(btsamps, FUN = median, simplify = TRUE)
mean(thetast)
```

Percentile interval of the median
===============
```{r}
median(stackloss$stack.loss)
quantile(thetast, c(0.025, 0.975))
```

Now, using the boot function
===============
```{r}
med_fun <- function(x, ind) median(x[ind])
med_boot <- boot(stackloss$stack.loss, med_fun, R = 2000)
boot.ci(med_boot, type = c("perc", "norm", "bca"))
```

```{r}
hist(med_boot$t, main="Stack loss for ammonia oxidation plant", xlab="Stack Loss", breaks = 20)
```
Note: *bca* = bias-corrected and adjusted

Use with the t-interval
=======================

- We usually use the *t*-statistic to calculate confidence intervals.

$$\bar{X} \pm t_{\alpha/2, df=n-1}\frac{S}{\sqrt{n}}$$

-  If we know that our outcome statistics will be bell shaped (e.g. symmetric with a shape similar to the normal), we can use the *t*-statistics along with our bootstrap 

$$statistic  \pm t_{\alpha/2, df=n-1} * SE(statistic)$$


Hypothesis testing
====================

Used to test if two groups are significantly different or if two groups are reasonably similar.  Standard method

- Collect information/data from the two groups and calculate a statistic for comparison.  e.g.
  $$\bar{X}_1 - \bar{X}_2$$
- Presume there is no difference between the groups ($H_0$).  Find the distribution of the statistic in 1.  e.g. assume *mean=0* and calculate *sd*
- Locate the observed value of the statistic with respect to the distribution found in 2. If the value is not in the main body of the distribution, then it provides evidence *against* the null hypothesis.  We usually compute the *p*-value to decide this.

Hypothesis testing with simulation
====================


-  Example: the common dosage for an anti-retroviral drug AZT is 300mg. Higher doses are potentially more effective, but also have more side effects. Question: are the side effects significantly higher?

1.  Calculate the difference in means between two groups: AZT with 300 mg and AZT with 600 mg dose.

```{r}
azt300 <- c(284, 279, 289, 292, 287, 295, 285, 279, 306, 298)
azt600 <- c(298, 307, 297, 279, 291, 335, 299, 300, 306, 291)
mean(azt300, digits=1)
mean(azt600, digits=1)
delta300600 <- mean(azt600) - mean(azt300)
delta300600
```

Significance with bootstrap
===========================

2.  Resample from the data to generate a distribution of differences.
    -  Presuming there are no differences, sample 10 from the *control* data to generate a *a300* group, and another 10 from the *control* to represent the *a600* group. (*Q: why 10?*)
    -  Calculate and save the differences in mean.
3.  Draw the *permutation distribution* of these differences. Locate the observed difference that you observed when you had two distinct datasets (300.3-298.4 = 10.9) and determine its *p-value* from the *permutation distribution*. If *p* is small, this is evidence against the null hypothesis

```{r}
set.seed(1234)
permdistfun <- function(azt){
  pdelta <- c()
  tf10 <- c(rep(FALSE, 10), rep(TRUE, 10))
  select <- sample(tf10, 10, replace = TRUE)
  azt3 <- azt[select]
  azt6 <- azt[!select]
  delta <- mean(azt6)-mean(azt3)
  delta
}
```


Now, apply bootstrap and to get the permutation distribution
=====
```{r}
azt <- c(azt300)
samples = 1000
pdist <- sort(replicate(samples,permdistfun(azt)))
```
```{r, echo=FALSE}
summary(pdist)
hist(pdist, breaks=seq(-20, 20, by=1))
```


Find the p-value of the observed difference
=================
```{r}
qdist <- max(which(pdist<delta300600))/samples
pvalue <- min(qdist, 1-qdist)
pvalue
```

Compare to normal hypothesis testing
==========================

- the `t.test` function can be used for one or two sample t-tests on vectors of data
- Q: how would you use this for a paired t-test?

```{r}
t.test(x=azt300, y=azt600)
```

-  Why the difference?


Another example - Categorical variables
====================

- Claim ($H_A$) is that a treatment leads to a change in the population from the control.
- Null hypothesis ($H_0$) is that the treatment does not result in a change.
- Simulate the sample the size of a treatment, and determine the $p$ that observed values were seen.

Quadcopter rotor blades
==========

A quadcopter company is considering a new manufacturer
for rotor blades. The new manufacturer would be more expensive but their higher-quality blades are more reliable, resulting in happier customers and fewer warranty
claims. However, management must be convinced that the more expensive blades are worth the conversion before they approve the switch. 

If there is strong evidence of a more than 3\% improvement in the percent of blades that pass inspection, management says they will switch suppliers, otherwise they will maintain the current supplier. 

Data
=======

Rotor blade failures

Group           Pass    Fail
-------------- ------ --------
Current         899     101
Prospective     958     42

```{r}
rotor <- data.frame(pass = c(899, 958),
                    fail = c(101, 42))
pfailnull <- sum(rotor$fail[1])/sum(rotor)
```

Simulate assuming that all data is from the control group
==========================
```{r}
rotorsim <- function(i){
              successes <- sum(sample(x=0:1, size = 1000, 
                                      replace=TRUE, 
                                      prob=c(pfailnull, (1-pfailnull))))
}
rotorout <-sapply(1:10000, rotorsim)
```

Look at the histogram of the result and find the $H_A$
======================
```{r}
hist(rotorout, breaks = 100)
```

```{r}
print(length(rotorout[rotorout>958])/length(rotorout))
```


Processing time example
=======================

- Find the standard deviation of processing time
- Only one day of orders is available.

```{r}
machining <- data.frame(jobnumber=c(1,2,3,4,5,6,7,8,9,10),
                        processingtime = c(11, 29, 31, 3, 2, 9, 15, 20, 22, 25))
```

```{r}
samplemachine <- function(joblist){
  joblist <- machining
  joborder <- sample(x = joblist$jobnumber, size = length(joblist$jobnumber), replace = TRUE)
  totaltime <- sum(machining$processingtime[joborder])
  totaltime
}
```
```{r}
sampletime <- rep(0, 50)
for (i in 1:50){
  sampletime[i]<- samplemachine(machining)
}
hist(sampletime, main="Distribution of processing time")
```

Time step simulation
=======================

- Each round of simulation advances the simulation one time unit. e.g. one day.
- Contrast - Discrete event simulation advances the clock to the next event
- Monte Carlo models each round is independent of every other round

Structure of a simulation
==============

1. Set initial state
2. Run one time unit
3. Save end state
4. End state becomes the initial state for the next round
5. Check if (simulation) stopping condition is met
    - Number of iterations/time periods
    - Specific state reached

Inventory model example
========================

- One of the standard models is periodic inventory $S,s$ model
- At the beginning of each period any deliveries occur.
- Each period sees a random demand with a given probability distribution
- At the end of the period, compare inventory $i$ to a reorder point $s$
    -  If inventory $i$ is less than $s$, order $q = S - i$
    -  $S$ and $s$ are calculated based on demand, order lead time, and cost factors.
- Calculate cost of the period including inventory holding and ordering cost
-  Assume daily demand is Poisson

Set up initial conditions and cost structure
========================
```{r}
S <- 50
s <- 10
i <- S # start at S
meandemand <- 8
K <- 10 # cost of orders
h <- 1 # cost of storing inventory
stockout <- 50 # stockout penalty
delivery = 0
```

Set up statistics collection
=============================
```{r}
nstockouts <- 0 # count times when inventory goes to zero
inventorydays <- 0 # sum of inventory holding
norders <- 0 # count orders made
```

Implement one time period
=====================

- Implement one day
- Run several times to make sure it works.

```{r}

dailycost <- 0
if (delivery > 0){
  i <- i + delivery
  delivery <- 0
}
daydemand <- rpois(1, lambda = meandemand)
if (daydemand>i){
  nstockouts <- nstockouts + 1
  dailycost <- dailycost + stockout
}
i = max(i-daydemand, 0)
inventorydays <- inventorydays + i
dailycost <- dailycost + h*i
if (i < s){
  delivery <- S-i
  norders <- norders + 1
  dailycost <- dailycost + K
}
print(c(daydemand, i, delivery, inventorydays, nstockouts, norders, dailycost))
```

Turn the time period code into a function, then run one replication
===================================================================


- Run one replication
    - One year = 250 working days
    - Use a for loop (why can you not vectorize the whole thing)
- Update statistics as you go

```{r}
nstockouts <- 0 # count times when inventory goes to zero
inventorydays <- 0 # sum of inventory holding
norders <- 0 # count orders made
cost <- 0
for (days in 1:250){
  dailycost <- 0
  if (delivery > 0){
    i <- i + delivery
    delivery <- 0
  }
  daydemand <- rpois(1, lambda = meandemand)
  if (daydemand>i){
    nstockouts <- nstockouts + 1
    dailycost <- dailycost + stockout
  }
  i = max(i-daydemand, 0)
  inventorydays <- inventorydays + i
  dailycost <- dailycost + h*i
  if (i < s){
    delivery <- S-i
    norders <- norders + 1
    dailycost <- dailycost + K
  }
  cost <- cost + dailycost
}
print(c(cost, nstockouts, norders, inventorydays))
```

Run many replications to get a distribution of outcomes
==================

- Save results to lists.
- Turn list into dataframe for further analysis

```{r}
# Initialize statistics for analysis with empty lists
stockoutsperyear <- c()
inventorydaysperyear <- c()
ordersperyear <- c()
costperyear <- c()

for (rep in 1:1000){  # 1000 replications
  nstockouts <- 0 # count times when inventory goes to zero
  inventorydays <- 0 # sum of inventory holding
  norders <- 0 # count orders made
  cost <- 0  
  for (days in 1:250){
    dailycost <- 0
    if (delivery > 0){
      i <- i + delivery
      delivery <- 0
    }
    daydemand <- rpois(1, lambda = meandemand)
    if (daydemand>i){
      nstockouts <- nstockouts + 1
      dailycost <- dailycost + stockout
    }
    i = max(i-daydemand, 0)
    inventorydays <- inventorydays + i
    dailycost <- dailycost + h*i
    if (i < s){
      delivery <- S-i
      norders <- norders + 1
      dailycost <- dailycost + K
    }
    cost <- cost + dailycost
  }
  stockoutsperyear <- c(stockoutsperyear, nstockouts)
  inventorydaysperyear <- c(inventorydaysperyear, inventorydays)
  ordersperyear <- c(ordersperyear, norders)
  costperyear <- c(costperyear, cost)
}
sssimulationoutput <- data.frame(stockouts = stockoutsperyear,
                                 inventorydays = inventorydaysperyear,
                                 orders = ordersperyear,
                                 cost = costperyear)
```

Analyze output
==============

```{r}
ggplot(sssimulationoutput) + geom_histogram(aes(cost)) +
  ggtitle("Annual cost for S,s simulation")
```

Summary
======

-  Simulation often used when some data is unobservable.
    -  Ask the question: could I have seen the result I saw if *X* was true?
-  Resampling can be used for hypothesis testing in the case of little data or if normal assumption is not true.
    -  Bootstrapping can be used to identify what the system would look like if more data were available or if the source population changes.
