Lecture 10: Data Aggregation
========================================================
author: IE 0015 Spring 2016
date: March 2016


Tidy data
==============
type:section

Data preparation
===================

-  *Data preparation* involves *cleaning* and *preparing* the data.
  -  *cleaning* - correcting mistakes and formatting the data into a usable form.
  -  *preparing* - organizing the data for analysis.
-  Some tasks involved in data preparation.
  1.  Checking for outliers
  2.  Error checking
  2.  Parsing dates
  3.  Missing value imputation
  4.  *Structuring data to facilitate analysis*
  
Tidy data
========

-  Tidy data is a set of principles to organize data values within the data set.
-  Makes data cleaning and preparation easier because you have an end goal.
-  Makes data exploration and analysis easier.
-  Makes it easier to develop data analysis tools that work together.

Why a philosophy of data preparation
=====================

1.  Real world datasets are often hard to work with.
  -  Data is often organized for presentation, not analysis.
  -  Data is collected and reported as a goal in itself, not as a first step in analysis.
  -  So to work with the data, we need to manage it first.
2.  Many of these principles are the same as principles in relational database design. (IE 1014)

Tidy data in R
====================

-  In **R**, many packages work with `data.frame`, so they are designed with this philosophy in mind.
-  `A data.frame` is made up of *rows* (observations) and *columns* (variables).
-  Every data element is the value of a variable for an observation.
-  *Note: a lot of data are not presented this way!*

Examples of what you will see
==============

    | treatmenta  | treatmentb
--------------|----------------|-----------
John Smith | - | 2
Jane Doe  | 16 | 11
Mary Johnson  | 3 | 1


    | John Smith | Jane Doe  | May Johnson 
----|------------|-----------|---------------
treatmenta | - | 16 | 3
treatmentb | 2 | 11 | 1

- But these both have observations as columns
- Need to have each row be a single observation

Each row is only a single observation
=====================

  person     | treatment   | value
-------------|-------------|--------
John Smith | a | --
Jane Doe | a | 16
Mary Johnson | a | 3
John Smith | b | 2
Jane Doe | b | 11
Mary Johnson | b | 1



Do variables really define new observations?
==================

> -  When should variables be used to define a new observation?
> - Are variables related?
> - Are variables a function of another?
> - If yes, then the variables can be kept together in a single observation.
> - It is easier to make comparisons across groups of observations rather than groups of columns. 

What does Tidy data look like
===============

1.  Each variable forms a column.
2.  Each observation forms a row.
3.  Each type of observational unit forms a table

- Note: in database design, this corresponds to Cobb's Third Normal Form.
- *Messy data* is any other arrangement.
  -  When doing statistical analysis, you will have to do organizational contortions before applying statistical methods.
  
Some advantages to tidy data
===============================

-  Experimental design is apparent
  -  Sort by descriptive variables to show the experimental design
-  Method to analyze each variable is the same
  -  Only change is in your SELECT or equality conditions

Common ways data sets diverge from tidy data
==============

1.  Column headers are values, not variable names.
2.  Multiple variables are stored in one column.
3.  Variables are stored in both rows and columns.
4.  Multiple types of observational units are stored in the same table.
5.  A single observational unit is stored in multiple table.

Column headers are values, not variable names.
=============

-  Common because data is often reported for display, not analysis.
   -  Advantage because it is efficient in space.  
-  Often row and column headers are both variables, and the data element is a value in a table.
-  We can correct this by stacking the columns into a longer table, this turns columns into rows (later we will call this *melt*. Also known as making a *wide* table into a *long* table.)


Multiple variables are stored in one column.
===================

-  Example, a data element `m14` refers to a male, age 14.
-  You cannot use this to analyze either gender or age.
-  Need to break this up into a column for gender and a column for age.

Variables are stored in both rows and columns.
==============

-  Often done to conserve space
-  Also often shows relationships between certain observations by laying them out side by side.
-  e.g. Each row is a week (e.g. week 1 of January) and there are columns for Mon, Tue, Wed, Thu, Fri, Sat, Sun
-  But to do any analysis other than the one demonstrated, you need to convert the columns into rows.

Multiple types of observational units are stored in the same table.
===============

-  Often done to conserve space.
-  You notice this because some data ends up being repeated in many rows.
-  E.g. Billboard music charts that identify a song, artist, label, a week, and rank for that week.  The artist and label repeated every time the song is on the chart.
-  Causes errors because of repetition, if you have a correction, it needs to be corrected everywhere.
-  Better to have a table for song, rank, and week, and a second table that includes data that does not change for that song, e.g. song, artist, label, release date, etc.



A single observational unit is stored in multiple tables.
=====================

-  Often because the data is collected for different reasons or by different sources.
-  Solution is to JOIN the tables.
  -  Use one table as a starting point, and add columns from each of the other tables.





Aggregation of data
=========
type:section

Aggregating data
================

-  We often want to look at summarized data across groups, not individual data points.
-  e.g. count instances, summations
-  `table` function accomplishes this goal.
-  `apply` family of functions can be used to work on arrays or lists.

Issues
======

-  Aggregating data hides information in the data, so typically do this after you have determined what aggregation is useful.
-  We aggregate to reduce the number of dimensions being presented, so do this because there are more dimensions to be analyzed than can be understood easily.
-  Aggregation is done because you have something that needs to be communicated and you are attempting to remove extra detail through summaries.  Make sure that what is removed is extra.

>  Everything should be a simple as possible, but no simpler.
>       - Einstein (paraphrase)



table
=====

-  Creates an array of values and counts
-  Can be turned into a `data.frame`

Use ACS as an example
============

```{r readingsqlite}
library(RSQLite)
#library(tidyr)
#library(dplyr)
con <- dbConnect(SQLite(), "../data/acs1yrPittsburgh01701.sqlite")
sql <- "SELECT *      
        FROM ss12hpa"
acsh <- dbGetQuery(con, sql)
sql <- "SELECT *      
        FROM ss12ppa"
acsp <- dbGetQuery(con, sql)
```

table summaries
=================

- Look at travel arrangements

```{r}
carpool <- acsp$JWRIP
cptable <- table(carpool)
cptable
```

Or make the table summary a data frame
==================

```{r}
as.data.frame(cptable)
```


Diversion:  recode variables
=======================

- In the ACS data, many of the variables are coded as integers ("1", "2", "3", etc)
- We would want to recode them with their values in English
- Use ``merge`` to do an operation similar to join


```{r}
worktransportation = data.frame(
              JWTR = c("bb", "01", "02", "03", "04", "05", "06",
                     "07", "08", "09", "10", "11", "12"), 
              worktransportation = c(NA, 
                    "Car, truck, or van",
                    "Bus or trolley bus",
                    "Streetcar", "Subway",
                    "Railroad", "Ferryboat",
                    "Taxicab", "Motorcycle",
                    "Bicycle", "Walked",
                    "Worked at home", "Other"))

acsp <- merge(acsp, worktransportation, all.x=TRUE, by='JWTR')
commutetable <- table(acsp$worktransportation)
as.data.frame(commutetable)
```




Thinking about aggregation
========================

-  What are the groups that are useful to aggregate on?
-  What is the nature of data to be operated on?
-  What is the desired end result.

The apply family of functions
=============================

-  In programming languages that have functional features (e.g. R, Matlab), we generally do not use for loops to loop through data.
-  If data is organized in a matrix, array, or vector, we can **map** a function to the data structure.
-  Apply the function so summarize the data into a single dimension.

Some members of the apply family of functions
===========================

Function name  | Description
--------------------|------------------
apply  |  Apply function over array margin
by     | Apply function to a data frame split by factors
lapply | Apply function over a list or vector (returns list)
sapply | Apply function over a list or vector (returns vector or matrix)
aggregate | Summaries over columns of a data frame.
tapply | Apply function over a ragged array

apply: 
=======

-  Apply function over array margins
-  *Margins* are the dimensions of the array (row = 1, columns = 2)

```{r}
# create a matrix of 10 rows x 2 columns
m <- matrix(c(1:10, 11:20), nrow = 10, ncol = 2)
# mean of the rows
apply(m, 1, mean)
# mean of the columns
apply(m, 2, mean)
# divide all values by 2
apply(m, 1:2, function(x) x/2)
```

by: data frame split by factors
======

-  Summarize data frame split by factors

```{r}
# Mean household income split by housing Tenure
tenurevalues <- data.frame(
                  TEN = c("", 1, 2, 3, 4), 
                  tenurevalues = c(NA, 
                                 "Owned with mortgage or loan",
                                 "Owned free and clear",
                                 "Rented",
                                 "Occupied without payment of rent"))
acsh <- merge(acsh, tenurevalues, by='TEN')
acsh$watercost <- as.numeric(acsh$WATP)
acsh$householdincome <- as.numeric(acsh$HINCP)
acsh$numpeople <- as.numeric(acsh$NP)
```

Results of grouping by a factor
=====
```{r}
by(acsh[,c('householdincome', 'numpeople', 'watercost')], acsh$tenurevalues, colMeans)
```

lapply
======
- Returns a list resulting from applying a function to the corresponding element of X

```{r}
# create a list with 2 elements
l <- list(a = 1:10, b = 11:20)
# the mean of the values in each element
l.mean <-lapply(l, mean)
typeof(l.mean)
l.mean[['a']]
```

sapply
======

- like `lapply` but returns a vector or matrix

```{r}
l.mean <- sapply(l, mean)
typeof(l.mean)
l.mean['a']
l.mean[1]
```

vapply
======

- `vapply` is similar to `sapply`, but has a prespecified type of return value.
- e.g. `fivenum` returns a summary of min, 1Q, median, 3Q, max

```{r}
l.fivenum <- vapply(l, fivenum, c(Min.=0, "1st Qu."=0, Median=0, "3rd Qu."=0, Max.=0))
class(l.fivenum)
l.fivenum
```

mapply
======

-  Multivariate version of `sapply`.  Applies the function to the first elements of each arguement, second element, etc.

```{r}
l1 <- list(a = c(1:10), b = c(11:20))
l2 <- list(c = c(21:30), d = c(31:40))
# sum the corresponding elements of l1 and l2
mapply(sum, l1$a, l1$b, l2$c, l2$d)
```


Groups based on one or more group variables
==============

- `aggregate`
- `tapply`

aggregate
==========

-  Summarize a columns based on defined groups

```{r}
library(reshape2)
library(ggplot2) #loads reshape2 package
data(diamonds)
summary(diamonds)
aggregate(diamonds[,c(1, 7)], diamonds[,c(2,3)], mean)
```

tapply
======

-  Processes a single vector based on the values of one or more grouping vectors

```{r}
maxcarat <- tapply(diamonds$carat, diamonds$color, max)
maxcarat
```
Mapping a function to a vector or list
====================

- `lapply` - Returns output as a list
-  `sapply` - returns output as a vector or matrix (if possible)
-  Note: returning a vector implies that order is important, e.g. the results are matched to another vector.

Example for a mapping
=============

-  Break out individual words for each sentence.
-  Unknown number of words in each sentence, so use a list for each sentence.

```{r}
text = c("R is a free environment for statistical analysis",
 "It compiles and runs on a variety of platforms",
 "Visit the R home page for more information")
result = strsplit(text, " ")
result
typeof(result)
```

Now, take the list and get the length of each sentence
==================

- Because we want the length to be associated with the sentence, use `sapply`

```{r}
nwords = sapply(result, length)
nwords
```

Mapping a function to a matrix or array
=====================

-  Because we often do analysis based on each element in a data frame, we often use `apply` on data frames.
-  Income per family member

```{r}
familypercapita <- function(acs){
  percapita <- as.numeric(acs[["HINCP"]])/as.numeric(acs[["NP"]])
}
acsh$FINCP <- as.numeric(acsh$FINCP)
acsh$HINCP <- as.numeric(acsh$HINCP)
acsh$NP <- as.integer(acsh$NP)
acsh$percapita <- apply(acsh, 1, familypercapita)
summary(acsh$percapita)
```


Mapping a function based on groups
=====

-  `aggregate`  for data frames
-  `tapply` for vectors



reshape2 package
=====

- similar to pivot tables
- create  *melted* version of data
- *cast* into an object with the desired orientation.
- Note: an evolution of the `reshape` package

Wide data vs long data
======

- There are two ways of storing data about an observation
  -  *wide* - one row for each entity id, with a column with data representing each feature of the entity
  -  *long* - one row for each observation, with columns for entity id, feature observed, and the data observed.

Air quality
============
```{r}
head(diamonds)
```

wide to long
======
```{r}
# Note: package reshape2 loaded by ggplot2
dl <- reshape2::melt(diamonds)
head(dl)
```

long to wide
=====
-  To convert from long to wide, use `cast`
-  Need to identify the dataset
-  Formula that represent the variables that appears in the columns (a factor) and in the rows (`variable` to indicate all)
-  And a summary function (default `count`)

```{r}
dw <- reshape2::dcast(dl, color + cut ~ variable, mean)
head(dw)
```


