---
title: 'Lecture 11: Transformations and Modeling'
author: "IE 0015"
date: "March 25, 2017"
output: 
  pdf_document: default
  slidy_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Notes on programming
====================

Three key steps to creating a new function
===========

1. You need to pick a name for the function. Here I used `rescale01` because this function rescales a vector to lie between 0 and 1.

2. You list the inputs, or arguments, to the function inside function. Here we have just one argument. If we had more the call would look like `function(x, y, z)`.

3. You place the code you have developed in body of the function, a `{` block that immediately follows `function(...)`.

Starting points
=======

-  Write a process map. The process map covers the logic of the function. Make sure you understand the logic, then try to figure out the details in implementing it.
-  Make a function after figuring out how to make it work with a simple input. 
  -  Start a code block that you will turn into a function by assigning values to what will be the parameters
  -  Make this work, then try it with different parameter inputs
  -  For testing, make each possible outcome occur, so you know it works every time.
- Itâ€™s easier to start with working code and turn it into a function than   to create a function and then try to make it work.
- Note: If you know how to use debugging tools from other IDE (e.g. MS Visual Studio, Eclipse), they are available in R Studio as well.
  -  If you do not, adding print statements to show the parameters being passed to functions that are not working is helpful.

Transforming data
============================

- We transform data because it allows us to more clearly identify patterns in the data.
- We think there is a relationship, a transform allows us to see if the relationship is strong.
- Many numerical methods (e.g. linear regression) can work better if the model is transformed.

Some transforms you already know
===========================

- Filtering - Examine a specific part of the dataset or remove outlier cases.
  - Or filter to look at outliers more closely.


```{r, echo=FALSE}
library(ggplot2, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(modelr) # this is in tidyverse, but we have not used it before
```
```{r}
data(diamonds)
nrow(diamonds)
ggplot(diamonds, aes(x,y)) + geom_bin2d() 
```

```{r}
diamonds_ok <- filter(diamonds, x>0, y>0, y < 20)
ggplot(diamonds_ok) + geom_bin2d(aes(x,y)) + geom_abline(slope=1, color="white", alpha=0.5)
```

Logical operators for filters
===========

- `x==y`: x and y are equal.
- `x!=y`: x and y are not equal.
- `x %in% c("a", "b", "c")`: x is one of the values in the set right hand side.
- `x > y, x >= y, x < y, x <= y`: greater than, greater than or equal to, less than, less than or equal to.



And combine them with logical operators:
======

- `!x` - Not x, flips TRUE and FALSE
- `x&y`: TRUE if both x and y are TRUE.
- `x|y`: TRUE if either x or y (or both) are TRUE.
- `xor(x,y)`: TRUE if either x or y are TRUE, but not both (exclusive or).

Transforming data
=================

- Some typical transformations

- Log transforms - turns multiplicative (compounding) relationships into additive relationships.
  - Often used to compress data that ranges over several orders of magnitude.
- Relative difference - Use log(x/y) instead of the actual values x and y. (note: this is better than x/y because it is symmetric, the order of x and y does not matter)
- Integrating or differentiating to transform variables.  E.g. transform distance and time to speed or acceleration.
- Cartesian (rectangular) to/from polar coordinates
- Centering and scaling 
  - Converting to standard normal subtracting from a mean and dividing by standard deviation
  - Converting point to a percentile of the entire range
  
Rescale example from last lecture
==========

```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
rescale01(c(0, 5, 10))
```

Note: statistical software and rescaling
==============

- R, SAS, SPSS do this automatically in their statistical routines.
- For other statistical software, the accuracy of results may be improved if you do this.


In dplyr
============

- Use group_by and summarize to calculate needed summary statistics
- Use mutate to do the transformation

Use diamonds example
==============

Show how summary statistics can be used to explain odd data.

Modeling
===========

The Art of Modeling
===================

> -  We use models in an attempt to gain insights about some aspects of the real world.
> -  Assumes *a priori* the existence of *ground truth* which an impartial and omniscient observers would agree upon.
> -  We start by deciding what aspect of the real world we are interested in.
  -  Narrow the focus of the model.

Some definitions
============

> -  *System* is a set of elements that interact or interrelate in some fashion.
> -  *Entities* are elements that make up the system
> -  If an element does not interact or interrelate with other elements of the system, it is irrelevant to our goal.
> -  A system may be made up of *sub-systems*, and may be a sub-system for another system.

What is a model
==========

-  A *model* is a system we use to study in place of another system.
-  The cost of building and studying a model is often a small fraction of the cost of experimenting with the real system.
-  Benefits
	-  Mitigate risk
	-  Cause events to occur on demand to develop experience

Types of models
==========

-  Physical models - Wind tunnels.  Concept cars.
-  Mechanical models - Anatomy models for medicine.
-  Mathematical equations - e.g. trajectory of a falling object.
-  *Computer simulation* - A model that is implemented as a computer program.

Purpose of models
===========

> -  To mimic or describe the behavior of the system being modeled.
> -  It can be *simplified* or *abstracted*
> -  It should describe the *essential* characteristics of the system.
> -  We evaluate the model on how well its *outputs* match the observed outputs of reality.
> -  Then, we want to see how the model responds when we make changes.
> -  So we want to *observe* outputs and be able to *control* the model through inputs.
> -  The model is thus created to address a specific question.
> -  Insight, not numbers

Effectiveness of models
=====================

-  The model is a representation of the real system.

-  By necessity, the model is a simplification
        - *The best material model for a cat is another cat* - Wiener and
Rosenblueth
        - *All models are wrong, some models are useful* - George Box
        -  *The purpose of computing is insight, not numbers* - Richard Hamming

-  Our goal is make models that are useful for a particular purpose.

Models for inference
=========

\begin{figure}
\includegraphics[width = 0.6\textwidth]{figures/modelinsight}
\caption{A model yields insights and inferences}
\end{figure}


Modeling for data analysis
===============

- Remove the so-what factor
- Identify effects beyond what is known

Creating a model
===============

1. Model family
  - Express a pattern you want to capture
  - e.g. *linear*, *quadratic*, *exponential*, *linear program*
  - e.g. System structure (*queue*, *inventory*)
2. Fitting model
  - Take a generic model family and make it specific
  - Determine parameters

Diamond example
===========

-  Look at plot of carat vs price
-  Is this linear
> - Look at the distributions on both axis and the relationship?
> - What would make it linear?


```{r}
dplot <- ggplot(diamonds)
dplot + geom_point(aes(x=carat, y=price))
```

Log-log plot
===============

- Plot with log of carat for x axis, log of price for y axis

```{r}
dplot + geom_point(aes(x=log(carat), y=log(price)))
```

Using dplyr (if the transform was not this easy)
=================

- Add in a linear model (lm) to the curve
```{r}
diamonds2<-diamonds %>% 
  mutate(lcarat = log2(carat), lprice = log2(price))
ggplot(diamonds2, aes(x=lcarat, y=lprice)) + 
  geom_bin2d() +
  geom_smooth(method="lm", se=FALSE, size=2, color="yellow")
```

Linear modeling
============

- The other use of models is to account for aspects that you already know are true, but you want to examine the influence of other variables.
-  Let's look at clarity
```
a measurement of how clear the diamond is (I1 (worst), SI1, SI2, VS1, VS2, VVS1, VVS2, IF (best))
```
```{r}
dplot+geom_boxplot(aes(x=clarity, y=price))
```

Removing the influence of known predictors
==============================

-  Condition on another variable (carat)
-  In design of experiments, this is called *blocking*
-  We use linear regression models to analyze this type of experiment.

Experimental design
===================

Randomized experiments are built on four principles. If we cannot make a perfect experiment, we have to think about how violating these principles effects our analysis of data.

- Controlling - We assign observations to treatment groups, and try to control for differences in groups.
- Randomization - Randomize assignments of observations to treatment groups.
- Replication - Observe more cases so that we can more accurately estimate the effect of explanatory variables on response.
- Blocking - If we suspect that variables, other than the treatment, influence the response, we may group observations by this variable and then randomize assignment of these observations to treatment groups.

Linear models
================

- Multiple linear regression
- Response (dependent) variable
- Explanatory (independent, treatment) variable
- Blocking (independent, but not treatment)

$$y = Ax + b$$

Implementing linear models in R
============

- `lm` function
- Takes a model as input
  - `response ~ explanatory variables`
  - Left unsaid is a constant term
  - `response ~ explanatory variables - constant`

```{r}
lmcarat <- lm(lprice ~ lcarat, diamonds2)
summary(lmcarat)
```

Visualizing models
===========

-  Look at clarity
```{r}
dplot+geom_boxplot(aes(x=clarity, y=price))
```

Account for carat
==================

```{r}
lmclarity <- lm(lprice ~ lcarat + clarity, diamonds2)
summary(lmclarity)
```
Model summaries
=============

-  Look at points that do not fit the model
-  See if errors are related to a specific factor

```{r}
diamonds2$lresiduals <- lmcarat$residuals
#diamonds2 %>%
#  add_residuals(lmcaret, "lresiduals") # add_residuals is in modelr
ggplot(diamonds2, aes(lcarat, lresiduals)) + 
  geom_bin2d()
```

Look to see if residuals correspond to a specific variable
====
```{r}
ggplot(diamonds2, aes(cut, lresiduals)) + geom_boxplot()
```
```{r}
ggplot(diamonds2, aes(color, lresiduals)) + geom_boxplot()
```
```{r}
ggplot(diamonds2, aes(clarity, lresiduals)) + geom_boxplot()
```

Put everything into a single model
====
```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
```

Plot the effects of each individual factor after all other variables are accounted for
====

-  For each variable, `data_grid` (from `modelr` library) assumes that the other variables are at their median value
-  What is the predicted value of an observation with that variable of the treatment variable being examined

```{r}
gridcut <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
gridcut
```

Now the same for color and clarity
=====

```{r}
gridcolor <- diamonds2 %>% 
  data_grid(color, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
gridcolor
```

```{r}
gridclarity <- diamonds2 %>% 
  data_grid(clarity, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
gridclarity
```
