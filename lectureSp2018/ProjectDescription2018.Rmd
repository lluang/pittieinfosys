---
title: "Project  Description"
author: "Information Systems"
date: "Spring 2018"
output:
  pdf_document: default
  html_document: default
---


1.  Identify a large, complex data set
  -  Large - Larger than you can take the time to look at the entire set in Excel.
  -  With diversity in the data fields (There should be a number of relevant data fields. You may need to get two data sources that cover the same entities to do this.)
  -  **Co**ntext
  -  **N**eeds
  -  **V**ision
  -  **O**utcome
2.  Process it
  -  The data must need processing
  -  Missing values
  -  Data entry errors
  -  Collapsing categories
3.  Summarize it
  -  Data summaries
  -  Visual
4.  Tell a story
5.  Show a picture
  -  Make it pretty.
  
Timeline
--------

1.  Form team and propose topic. Identify a data set(s) and a potential CoNVO - February 8
  -  One paragraph discussing a point of view (hypothetical client) and the goal of the project.  Then present the CoNVO statement.
2.  Exploratory data analysis - March 15
  -  Initial graphical view of data set.  There should be at least three dependent variables.
  -  Describe data according to Volume, Variety, Velocity, Veracity
    -  Volume - How much is there?
    -  Variety - How much and what variety is available about each observation?
    -  Velocity - Is data changing over time?
    -  Veracity - Is the data correct or are there questions about its accuracy or meaning?
  -  Refine CoNVO
3.  Final Report April 19,  Presentations April 20, 21 in lab (note: if teammates are in different lab sessions, I will pick one to present in)
4.  Extra credit. If you had to learn how to use an R package using data types and methods we did not cover in class, write one or two pages about the package.  Check with me to make sure that the package is significant enough.  E.g. Mapping or GIS packages for geographical data.

Inspiration
============

The ESPN run website FiveThirtyEight has numerous data driven articles that are similar in spirit to what the class project would be. They usually describe the setting, the data, and the analysis in every article. http://fivethirtyeight.com/

Data sources
------------

- Western PA Regional data Center - http://www.wprdc.org/  Housed at the University of Pittsburgh Center for Urban and Social Research. Partnership with City of Pittsburgh, Allegheny County, Pitt, and Mellon Foundation. Intended to be a central source for publically available data put out by local government. Inspired by similar efforts in Chicago, New York, and those hosted at Socrata https://www.socrata.com/
    -  If you do a project focused on local issues and using WPRDC data, they would like know. They may also be able to connect you with a group that is interested in what you are working on.

- American Community Survey - http://www.census.gov/acs/www/ - Detailed questionaire given to 1% of the population annually in the U.S.   Questionaires are de-identified and located according to geographies at the census tract level and larger.

- American Time Use Survey - http://www.bls.gov/tus/ The American Time Use Survey (ATUS) measures the amount of time people spend doing various activities, such as paid work, childcare, volunteering, and socializing.

- National Immunization Survey and National Immunization Survey (Teen) http://www.cdc.gov/nchs/nis.htm - Survey given on health habits and experiences.  Focuses on immunization coverage.

- Project Tycho - https://www.tycho.pitt.edu/  Data on infectious diseases at national, and global scales.  Note: There is an annual undergraduate student competition over the spring sponsored by the University of Pittsburgh Graduate School of Public Health that looks for innovative ways of working with Project Tycho data.

- Quandl is a site that has curated (cleaned and processed into a usable format) data sets of a wide range of topics. Mostly economic, financial, and demographic (its primary paid audience are people working in finance). Most non-realtime finance data are freely available.

https://www.quandl.com/

- Sports - Most sports have websites that collect a wide range of detailed statistics accessable by enthusiasts.


